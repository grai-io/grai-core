---
title: "BigQuery"
description: Grai BigQuery Integration
---

import Image from "next/image";
import { BigQueryLogoIcon } from "../../components/Integrations";
import InlineLogo from "../../components/InlineLogo";

<InlineLogo logo={<BigQueryLogoIcon />} title="BigQuery" />

The BigQuery integration synchronizes metadata from your BigQuery datawarehouse into the data lineage graph.

## Web App

<Image
  src="/images/docs/core/integrations/bigquery.png"
  height={600}
  width={1200}
  alt="BigQuery Integration"
/>

### Fields

| Field              | Value                                                                 | Example         |
| ------------------ | --------------------------------------------------------------------- | --------------- |
| Name               | Name for connection                                                   | Google BigQuery |
| Namespace          | Namespace for the connection, see [namespaces](/concepts/namespace)   | default         |
| project            | GCP project id                                                        | grai-demo       |
| dataset            | BigQuery Dataset Id, or multiple datasets seperated by a comma (`,`)  | jaffle_shop     |
| credentials        | JSON credentials for service account, see [Credentials](#credentials) |                 |
| Log Parsing        | Choose to enable log parsing, see [Lod Parsing](#log-parsing)         |                 |
| Log Parsing Window | The number of days to read logs from, see [Log Parsing](#log-parsing) | 7               |

### Credentials

1. Create a service account [https://cloud.google.com/iam/docs/creating-managing-service-accounts](https://cloud.google.com/iam/docs/creating-managing-service-accounts).

2. Add the following permissions to your service account:

- BigQuery Data Viewer
- BigQuery Job User

3. Generate json credentials for your service account [https://developers.google.com/workspace/guides/create-credentials#service-account](https://developers.google.com/workspace/guides/create-credentials#service-account).

4. Copy and paste the json into the [credentials] field.

### Log Parsing

Optionally the BigQuery integration can read logs from BigQuery to determine which tables are related to each other.

You will need to grant the service account the following additional permission:

- Logs Viewer

Logs are read over a window of one or more days, to capture relevant database logs. For example if you have a daily batch job, you could set the window to one day.

## Python Library

### Installation

Install BigQuery Grai package with pip

```shell copy
pip install grai-source-bigquery
```

This installs the Grai BigQuery integration, which is now ready to run in python

### Connecting & Syncing

The integrations comes equipped with the client library already but we will need a python terminal or Jupyter Notebook to execute a few commands to establish a connection and begin querying the server.

Spin up your favorite python terminal then:

```python copy
import os
from grai_source_bigquery.base import update_server
```

For now we will use the default user credentials though you are free to create a new user / api keys from the server admin interface at http://localhost:8000/admin.

```python copy
client = ClientV1("localhost","8000", username="null@grai.io", password="super_secret")
```

Now we can update the server with data from any BigQuery source. In order to do so you will need to pass credentials and namespace into the update_server function.
Namespace is used to uniquely identify the nodes and when used consistently will allow you to add to the node from any source.

Using example variables, in order to update the server with your metadata, simply run:

```python copy
update_server(client, project="[your_project]", dataset="[your_dataset]", credentials="[your_credentials]", namespace="[your_grai_namespace]")
```

```python copy
update_server(client, project="[your_project]", dataset=["[your_dataset]", "[your_second_dataset]"], credentials="[your_credentials]", namespace="[your_grai_namespace]")
```
